<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta charset = "UTF-8">
    <meta name = "keywords" content = "Michael, Nasello, Waterloo, Engineering, University of Waterloo,">
    <meta name = "viewport" content = "width=device-width, initial-scale=1">
    <meta name = "author" content = "Michael Nasello">
    <meta name = "description" content = "On this page, you can find details about me, my work experience, and some of
        the projects I've completed or am currently working on.">

    <title>Michael Nasello</title>

    <link rel="stylesheet" href="css/bootstrap.css">
    <link rel="icon" href="images/icon.png">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="css/style.css">

    <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>

</head>

<nav class = "navbar navbar-expand-lg navbar-light bg-light static-top mb-5 shadow" id = "home">
    <div class = "container">
        <a class = "navbar-brand" href = "#home">
            Michael Nasello &nbsp &nbsp
            <img style = "width: 30px" src = "images/icon.png">
        </a>

        <button class = "navbar-toggler" type = "button" data-toggle = "collapse" data-target = "#navbarResponsive"
                aria-controls = "navbarResponsive" aria-expanded = "false" aria-label = "Toggle navigation">
            <span class = "navbar-toggler-icon"></span>
        </button>
        <div class = "collapse navbar-collapse" id = "navbarResponsive">
            <ul class = "navbar-nav ml-auto">
                <li class = "nav-item active">
                    <a class = "nav-link" href = "#home">Home
                        <span class = "sr-only">(current)</span>
                    </a>
                </li>
                <li class = "nav-item">
                    <a class = "nav-link" href = "#about-me">About Me</a>
                </li>
                <li class = "nav-item">
                    <a class = "nav-link" href = "#work-experience">Work Experience</a>
                </li>
                <li class = "nav-item">
                    <a class = "nav-link" href = "#projects">Projects</a>
                </li>
                <li class = "nav-item">
                    <a class = "nav-link" href = "#featured-work">Featured Work</a>
                </li>
                <li class = "nav-item">
                    <a class = "nav-link" href = "#contact">Contact</a>
                </li>
            </ul>
        </div>
    </div>
</nav>

<a id="back2Top" title="Back to top" href="#"><i class = "fa fa-chevron-circle-up fa-lg"></i></a>

<script>
    $(window).scroll(function() {
        var height = $(window).scrollTop();
        if (height > 100) {
            $('#back2Top').fadeIn();
        } else {
            $('#back2Top').fadeOut();
        }
    });
    $(document).ready(function() {
        $("#back2Top").click(function(event) {
            event.preventDefault();
            $("html, body").animate({ scrollTop: 0 }, "slow");
            return false;
        });

    });
</script>

<script>
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
    anchor.addEventListener('click', function (e) {
            e.preventDefault();

            document.querySelector(this.getAttribute('href')).scrollIntoView({
                behavior: 'smooth'
            });
        });
    });
</script>

<script>
    // When the user scrolls the page, execute myFunction
    window.onscroll = function() {myFunction()};

    // Get the navbar
    var navbar = document.getElementById("home");

    // Get the offset position of the navbar
    var sticky = navbar.offsetTop;

    // Add the sticky class to the navbar when you reach its scroll position. Remove "sticky" when you leave the scroll position
    function myFunction() {
      if (window.pageYOffset >= sticky) {
        navbar.classList.add("sticky")
      } else {
        navbar.classList.remove("sticky");
      }
    }
</script>

<body>

    <div class = "container" id = "body-id">

        <div class = "card border-0 shadow my-5">
            <div class = "card-body p-5">

                <div class="container" id = "jumbo">
                    <div class="jumbotron bg-cover text-white" style = "background-image: linear-gradient(to bottom, rgba(30,30,30,0.6) 0%,rgba(30,30,30,0.8) 100%), url(videos/background-gif.gif)">
                        <div class="container">

                            <h1 class="display-4 animate-pop-in pop-title">Michael Nasello</h1>
                            <p class="lead animate-pop-in pop-secondary">Welcome to my website! Here I share details about me, my work experience, and some of my projects.</p>
                            <hr class="my-4 animate-pop-in icon-title" style = "border-color: white">

                            <div class="container animate-pop-in pop-secondary">
                                <div class="row">
                                    <div class="col-md">
                                        <ul class="social-icons">
                                            <li><a title = "LinkedIn" class="linkedin" href="https://www.linkedin.com/in/michael-nasello" target = "_blank"><i class="fa fa-linkedin"></i></a></li>
                                            <li><a title = "GitHub" class="facebook" href="https://github.com/MichaelNasello" target = "_blank"><i class="fa fa-github"></i></a></li>
                                            <li><a title = "Email" class="twitter" href="mailto:mlnasell@uwaterloo.ca"><i class="fa fa-envelope"></i></a></li>
                                            <li><a title = "Resume" class="dribbble" href="https://drive.google.com/open?id=1oScBNeyEuKXIX5FqIq0hdXf17sW3vygC" target = "_blank"><i class="fa fa-file"></i></a></li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                            
                        </div>
                    </div>

                </div>

                <br>

                <h3 id = "about-me" class = "font-weight-light animate-pop-in pop-title" style = "padding: 0px">About Me</h3>
                <hr>
                <p class = "animate-pop-in pop-secondary">
                    I am an individual with a passion for learning. To me, nothing is more exciting than struggling
                    through a problem and finding that breakthrough solution. While studying Mechatronics Engineering
                    at the University of Waterloo, I have been presented with countless opportunities to do so.
                    Collaborations with classmates has led to my introduction into several interesting areas, including
                    Web Development, Computer Vision, and Machine Learning.

                    <br><br>

                    Outside of the classroom, I use my time to
                    develop skills in these areas. Machine Learning is a field in which I have spent a significant
                    amount of time. From watching video lectures, reading articles, and learning the mathematics behind
                    model training, I have become competent in the area and an active practitioner.

                    <br><br>

                    In my free time, I enjoy working out, running, and recreational play of golf, tennis, and soccer.
                </p>

                <h3 id = "work-experience" class = "font-weight-light animate-pop-in pop-title">Work Experience</h3>
                <hr>

                <ul class = "nav nav-pills mb-3 animate-pop-in pop-secondary" id = "pills-tab" role = "tablist">

                    <li class = "nav-item">
                        <a class = "nav-link active" id = "pills-abr-tab" data-toggle = "pill" href = "#pills-abr" role = "tab" aria-controls = "pills-abr" aria-selected = "true">Applied Brain Research</a>
                    </li>
                    <li class = "nav-item">
                        <a class = "nav-link" id = "pills-nrc-tab" data-toggle = "pill" href = "#pills-nrc" role = "tab" aria-controls = "pills-nrc" aria-selected = "false">National Research Council Canada</a>
                    </li>
                    <li class = "nav-item">
                        <a class = "nav-link" id = "pills-vista-tab" data-toggle = "pill" href = "#pills-vista" role = "tab" aria-controls = "pills-vista" aria-selected = "false">Vista Solutions</a>
                    </li>

                </ul>
                <div class="tab-content animate-pop-in pop-secondary" id="pills-tabContent">

                    <div class="tab-pane fade show active" id="pills-abr" role="tabpanel" aria-labelledby="pills-abr">

                        <br>

                        <h4>Deep Learning Developer<img id = "canada-flag-default" style = "width: 50px; margin-left: 30px" src = "images/abr-logo.png"> </h4>

                        <img id = "canada-flag" style = "width: 50px" src = "images/abr-logo.png">

                        <p class="card-text"><small class="text-muted">September 2020 - December 2020 <i class = "fa fa-at"></i> Waterloo, ON</small></p>

                        <strong>Employer Evaluation: EXCELLENT</strong>

                        <br><br>

                        During my time at Applied Brain Research (ABR), I was a valued contributor to their newest
                        product, NengoCloud: a cloud service for training power-conscious Keyword Spotters targeting
                        various hardware backends.

                        <br><br>

                        My contributions to NengoCloud began with market research, forging a direction for the new
                        product. I compiled a list of potential hardware candidates to support today’s popular
                        Edge-AI devices. I completed additional market research, surveying popular cloud services
                        for training Edge-AI models and extracting a list of common user-facing options for their
                        clients. This research was condensed to a presentation I delivered to ABR leadership.

                        My coding time was dedicated to one specific hardware target: the Coral TPU. This work started
                        with sandboxing a compiler-compatible, feed-forward implementation of the RNN (to date, RNNs
                        are not natively supported by the TPU compiler). Following the support for ABR’s powerful
                        Legendre Memory Unit (LMU), my responsibilities included authoring initial drafts of host and
                        device code that provide the functionality to compile LMU models and run on-device testing.

                        <br><br>

                        I built a comprehensive Command Line Interface (CLI), with nested commands, for running the
                        full NengoCloud pipeline. I provided a proof-of-concept, training models on Google’s Speech
                        Commands v2 dataset; achieving ~97% training validation accuracy and, after model quantization
                        and compilation, ~95% on-device testing accuracy.

                        <br><br>

                        <a id = "fix" href = "https://appliedbrainresearch.com/" target = "_blank">
                            <button class = "btn btn-secondary" style = "padding-top: 10px; text-decoration: none">
                                ABR Website
                            </button>
                        </a>

                        <br id = "space1"><br id = "space2">

                        <a href = "https://www.youtube.com/watch?v=dDUIrZRsJiY" target = "_blank">
                            <button class = "btn btn-secondary" style = "padding-top: 10px; text-decoration: none">
                                NengoCloud
                            </button>
                        </a>

                    </div>

                    <div class="tab-pane fade" id="pills-nrc" role="tabpanel" aria-labelledby="pills-nrc">

                        <br>

                        <h4>Machine Learning Developer, Data Scientist<img id = "canada-flag-default" style = "width: 50px; margin-left: 30px" src = "images/canada-flag.png"> </h4>

                        <img id = "canada-flag" style = "width: 50px" src = "images/canada-flag.png">

                        <p class="card-text"><small class="text-muted">January 2020 - April 2020 <i class = "fa fa-at"></i> Ottawa, ON</small></p>

                        <strong>Employer Evaluation: EXCELLENT</strong>

                        <br><br>

                        During my time at the National Research Council (NRC), I worked on a project that uses
                        Machine Learning to forecast sea ice presence in several large Canadian bodies of water.
                        ML models incorporate
                        <a href = "https://arxiv.org/abs/1506.04214" target = "_blank">ConvLSTMs</a> and a
                        custom SIF-Net RNN architecture. For input, they take bitmaps of several environmental
                        conditions (e.g. precipitation, temperature, windspeed).

                        <br><br>

                        My contributions included adding to the existing model training pipeline and deploying final
                        products to AWS. I conducted rigorous experimentation with model inputs and
                        hyper-parameters to maximize performance. I wrote code for the deployment of the project to
                        AWS; using <a href = "https://aws.amazon.com/fargate/" target = "_blank">Fargate</a>, ice
                        presence forecasts are generated each day and available for viewing on a
                        static webpage that I developed.

                        <br><br>

                        I wrote a work term report, summarizing my contributions; this report is available via the
                        link provided.

                        <br><br>


                        <a id = "fix" href = "https://drive.google.com/file/d/1pU03hzEkUWYcNdCPgHg8C1bKGum3yEpT/view" target = "_blank">
                            <button class = "btn btn-secondary" style = "padding-top: 10px; text-decoration: none">
                                Work Term Report
                            </button>
                        </a>

                        <br id = "space1"><br id = "space2">

                        <a href = "http://nrc-sifnet-bucket.s3-website-us-east-1.amazonaws.com/" target = "_blank">
                            <button class = "btn btn-secondary" style = "padding-top: 10px; text-decoration: none">
                                NRC Website
                            </button>
                        </a>

                    </div>

                    <div class="tab-pane fade" id="pills-vista" role="tabpanel" aria-labelledby="pills-vista">

                        <br>

                        <h4>Machine Vision Support Engineer<img id = "vista-icon-default" style = "width: 50px; margin-left: 30px" src = "images/vista-logo.png"></h4>

                        <img id = "vista-icon" style = "width: 50px" src = "images/vista-logo.png">

                        <p class="card-text"><small class="text-muted">April 2019 - August 2019 <i class = "fa fa-at"></i> Windsor, ON</small></p>

                        <strong>Employer Evaluation: EXCELLENT</strong>

                        <br><br>

                        As a Machine Vision Support Engineer at Vista, I was responsible for developing Machine Learning
                        solutions for projects where traditional methods of Machine Vision could not perform at a
                        level required by the client. I worked on several projects during my co-op. I spent a
                        majority of my time carrying an Object Detection project to completion.

                        <br><br>

                        I was also responsible for training Vista Engineers and providing an introduction to Neural
                        Networks. I delivered a webinar presentation that introduced the general structure of Neural
                        Networks, the mathematics behind model training, and how these concepts can be implemented
                        into their custom applications.

                        <br><br>

                        I on-boarded Vista Employees with my work, prior to my departure, and trained the incoming
                        co-op student. I was requested for continual support related to Vista's Machine Learning
                        projects.

                    </div>

                </div>

                <br>

                <h3 id = "projects" class = "font-weight-light animate-pop-in pop-title">Projects</h3>
                <hr>

                <div class="container-fluid animate-pop-in pop-secondary">

                    <div role="alert" aria-live="assertive" aria-atomic="true" class="toast" data-autohide="false">
                        <div class="toast-header" style = "background-color: ghostwhite">
                            <img style = "width: 28px" src="images/icon.png" class="rounded mr-2" alt="...">
                            <strong class="mr-auto">- from MN</strong>
                            <small>just now</small>
                            <button type="button" class="ml-2 mb-1 close" data-dismiss="toast" aria-label="Close">
                            <span aria-hidden="true">&times;</span>
                            </button>
                        </div>
                        <div class="toast-body">
                            To view more projects in this section, scroll horizontally.
                        </div>
                    </div>

                    <script>
                        $('.toast').toast('show');
                    </script>

                    <div class="row flex-nowrap d-flex flex-row flex-nowrap overflow-auto">

                        <div class="col-lg-8">
                            <div class="card card-block">

                                <img src="images/auto-mini-cart.jpg" class="card-img-top" alt="...">
                                <div class="card-body">
                                    <h5 class="card-title">Autonomous Mini Cart</h5>

                                    <p class="card-text">

                                        The goal of this project is to build a Mini Cart, powered by a
                                        <a href = "https://www.raspberrypi.org/" target = "_blank">Raspberry Pi</a>,
                                        that can take directions without direct human intervention. A camera is mounted
                                        to the front of the cart chassis. Pictures are taken and processed through a
                                        Machine Learning algorithm to extract instructions.

                                        <br><br>

                                        Instructions include: 'go left', 'go right', 'go forwards', 'stay'. After a proof
                                        of concept is acquired, speed controls will be added. The user simply has to
                                        point in the direction of travel and the Mini Cart responds appropriately.

                                        <br><br>

                                        More information on this project will be posted in the
                                        <a href = "#featured-work">Featured Work</a> section of this page. To view the
                                        source code, a GitHub link is provided.

                                        <br><br>

                                        <a href = "https://github.com/MichaelNasello/Autonomous-Robot" target = "_blank">
                                            <button class = "btn btn-secondary">
                                                GitHub Repository
                                            </button>
                                        </a>

                                    </p>
                                </div>

                            </div>
                        </div>

                        <div class="col-lg-8">
                            <div class="card card-block">

                                <img src="images/NRC_SIFNET.png" class="card-img-top" alt="...">
                                <div class="card-body">
                                    <h5 class="card-title">Deployment of Sifnet ML Model</h5>
                                    <p class="card-text">

                                        When working at the NRC, I was asked to develop a method by which end users could
                                        access final products. Ice presence forecasts needed to be generated daily
                                        and available for download. I pioneered and finished the complete deployment
                                        pipeline of the project.

                                        <br><br>

                                        Using docker, I containerized the application and pushed
                                        the image to AWS. I then leveraged the flexibility of

                                        <a href = "https://aws.amazon.com/fargate/" target = "_blank">AWS Fargate</a>;

                                        scheduled tasks run daily and products are automatically uploaded to AWS s3. A
                                        website was created to display products and validation graphs of our models.

                                        <br><br>

                                        Below you can access the website I created to view and download final products.

                                        <br><br>

                                        <a href = "http://nrc-sifnet-bucket.s3-website-us-east-1.amazonaws.com/" target = "_blank">
                                            <button class = "btn btn-secondary">
                                                NRC Website
                                            </button>
                                        </a>

                                    </p>
                                </div>

                            </div>
                        </div>

                        <div class="col-lg-8">
                            <div class="card card-block">

                                <img src="images/cartpole-project.jpg" class="card-img-top" alt="...">
                                <div class="card-body">
                                    <h5 class="card-title">Reinforcement Learning with CartPole</h5>
                                    <p class="card-text">

                                        The goal of this project is to stand the pole upright for as long as possible; a
                                        traditional controls problem, but with the twist of using a Reinforcement Learning
                                        approach. Through the use of OpenAI Gym's environment, I am given control of the cart.
                                        The cart can move either left or right. My task is to determine, given a 4D vector
                                        [Position, Velocity, Angle, Angular Velocity], the action that will maximize the
                                        probability that the pole does not fall over, both in short and long term.

                                        <br><br>

                                        Below you can access my Github Repo and the documentation for OpenAI Gym.

                                        <br><br>

                                        <a href = "https://github.com/MichaelNasello/CartPole_Balance" target = "_blank">
                                            <button class = "btn btn-secondary">
                                                GitHub Repository
                                            </button>
                                        </a>

                                        <br id = "space3"><br id = "space4">

                                        <a href = "https://gym.openai.com/" target = "_blank">
                                            <button class = "btn btn-secondary">
                                                Open AI
                                            </button>
                                        </a>

                                    </p>
                                </div>

                            </div>
                        </div>

                        <div class="col-lg-8">
                            <div class="card card-block">

                                <img src="images/website-v1.png" class="card-img-top" alt="...">
                                <div class="card-body">
                                    <h5 class="card-title">Personal Website v1</h5>
                                    <p class="card-text">
                                        I developed a webpage written in virtually only HTML and CSS. No framework was used
                                        to help with the design of the page.

                                        <br><br>

                                        The website is still available via the link below.

                                        <br><br>

                                        <a href = "http://michaelnasello-old-website.ca.s3-website.ca-central-1.amazonaws.com/home" target = "_blank">
                                            <button class = "btn btn-secondary">
                                                Website v1
                                            </button>
                                        </a>

                                    </p>
                                </div>

                            </div>
                        </div>

                        <div class="col-lg-8">
                            <div class="card card-block">

                                <img src="images/cornerstone-project.png" class="card-img-top" alt="...">
                                <div class="card-body">
                                    <h5 class="card-title">Mechatronics Cornerstone Project</h5>
                                    <p class="card-text">
                                        This was a first-year, first-term design project for all Mechatronics Engineering
                                        students at the University of Waterloo. It was an open-ended project. We were given
                                        a lego set and an EV3 controller. Monitoring and defending personal space was the task
                                        we chose.

                                        <br><br>

                                        The final product surveyed an area and fired projectiles at approaching
                                        objects. Chassis composed of lego; source code written in RobotC. During the closing
                                        phase of the project, a final report was produced that summarized project scope,
                                        constraints and criteria, mechanical and software design and methods of testing.
                                    </p>
                                </div>

                            </div>
                        </div>

                    </div>
                </div>


                <br>

                <h3 id = "featured-work" class = "font-weight-light animate-pop-in pop-title">Featured Work</h3>
                <hr>

                <div class="accordion animate-pop-in pop-secondary" id="accordionExample">

                    <div class="card">
                        <div class="card-header" id="headingZero">
                            <h2 class="mb-0">
                                <button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseZero" aria-expanded="true" aria-controls="collapseZero">
                                    Autonomous Mini Cart &nbsp<i class = "fa fa-arrow-down"></i>
                                </button>
                            </h2>
                        </div>

                        <div id="collapseZero" class="collapse" aria-labelledby="headingZero" data-parent="#accordionExample">
                            <div class="card-body" style = "background-color: #616D7E;  color: #fff">

                                <h2>Autonomous Mini Cart</h2>

                                The Mini Cart is designed to follow directions without pre-programmed instructions.
                                The end user can simply point in the desired direction of travel and the robot will
                                react accordingly. Computer Vision and Machine Learning are used to determine
                                intended commands from instructor.

                                <br><br>

                                <h3>Raspberry Pi</h3>
                                <hr>

                                The Mini Cart is powered by a
                                <a href = "https://www.raspberrypi.org/" target = "_blank" style = "color: black">Raspberry Pi</a>; the Pi is
                                responsible for all ML computations, capturing pictures via the Pi camera, and reacting
                                by powering servo motors with GPIO (General Purpose Input Output) pins. A Python
                                <a href = "https://virtualenv.pypa.io/en/latest/" target = "_blank" style = "color: black">virtualenv</a>
                                was used to install and manage essential Python packages, including Tensorflow, Numpy,
                                Pillow, RPi.GPIO and Picamera.

                                <br><br>

                                <p style = "text-align: center">
                                    <img src = "images/pi.jpg">
                                </p>

                                <h3>Chassis</h3>
                                <hr>

                                The Mini Cart chassis holds the Pi, Pi-Camera, servo motors,
                                wheels, two power banks, and a breadboard circuit supporting drive functionality.
                                A custom camera mount was built and installed on the front of the mini cart.

                                <br><br>

                                <p style = "text-align: center" class = "col">
                                    <img src = "images/auto-robot1.jpg">
                                    <img src = "images/auto-robot2.jpg">
                                </p>

                                The circuit was designed, using a L293DNE driver motor chip to provide the capability
                                for forwards and backwards movement, at various speeds. I used
                                <a href = "https://business.tutsplus.com/tutorials/controlling-dc-motors-using-python-with-a-raspberry-pi--cms-20051"
                                target = "_blank" style = "color: black">this tutorial</a> for assistance.

                                <br><br>

                                <h3>Machine Learning</h3>
                                <hr>

                                A simple CNN was implemented to generate predictions. One issue specific to this project
                                was model size. It was impossible to load the original model (~400MB) into memory on the
                                Raspberry Pi; this is a common problem for ML 'at the edge'. Several steps were taken to
                                reduce the model size to ~2MB. The model was quantized to use float16 precision (from
                                float32). The model was further compressed using
                                <a href = "https://www.tensorflow.org/lite" target = "_blank" style = "color: black">Tensorflow Lite</a>.

                                <br><br>

                                In addition, images from the dataset were resized to 256 by 256 images (from 512 by 512).
                                This decreased the size of convolution layer outputs and number of parameters in dense
                                layers later in the network.

                                I created my own dataset, gathering approximately 400 images of myself pointing in
                                various directions. There was a 80 / 20 percent split of training and validation images,
                                respectively. On the validation set of 80 images, an eventual accuracy of 88% was
                                achieved.

                                <br><br>

                                Below you can observe the progress of training.

                                <br><br>

                                <p style = "text-align: center">
                                    <img src = "images/val_loss.png">
                                    <img src = "images/val_sparse_categorical_accuracy.png">
                                </p>

                                <h3>Final Product</h3>
                                <hr>

                                <div id = "robot-vid" class="embed-responsive embed-responsive-16by9">
                                    <video controls><source src = "videos/Autonomous-Robot.mp4" type = "video/mp4"></video>
                                </div>

                                <br>

                            </div>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-header" id="headingOne">
                            <h2 class="mb-0">
                                <button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseOne" aria-expanded="true" aria-controls="collapseOne">
                                    Reinforcement Learning with CartPole &nbsp<i class = "fa fa-arrow-down"></i>
                                </button>
                            </h2>
                        </div>

                        <div id="collapseOne" class="collapse" aria-labelledby="headingOne" data-parent="#accordionExample">
                            <div class="card-body" style = "background-color: #616D7E;  color: #fff">

                                <h3>Problem</h3>

                                The goal of this project was to develop a policy the CartPole can follow so that it stands upright. At each
                                time step, OpenAI Gym provides the cart's position, angle, velocity, and angular velocity. It is our
                                job to use this information to determine what action should be taken that will maximize the
                                probability that the CartPole remains standing upright. Possible actions are moving left or right.

                                <h3>Approach</h3>

                                <p>
                                    Reinforcement Learning was used to solve this problem. This concept is synonymous to
                                    positive/negative reinforcements in real life:
                                </p>
                                <p>
                                    <i>If a dog behaves, they receive a treat; if they misbehave, you put them in their cage.
                                         After time, the dog figures out what is considered good/bad behaviour
                                        based off of the consequences.
                                    </i>
                                </p>

                                <p>
                                    This approach can be used to our advantage when training AI. The reinforcement learning application
                                    consists of four entities:
                                </p>
                                <ol>
                                    <li>The environment (OpenAI Gym / Your house)</li>
                                    <li>The agent (CartPole / The dog)</li>
                                    <li>The action space (Move left or right / Behave or misbehave)</li>
                                    <li>The reward (Number / Give treat or put in cage)</li>
                                </ol>

                                <p>
                                    The approach for solving this problem is the following: train the CartPole to take actions that
                                    maximize its reward.
                                </p>

                                <h4>How is the network trained?</h4>

                                <p>
                                    For a given state, it is the network's job to output a vector of probabilities for taking each
                                    action in the action space. When training, we attempt to minimize the difference between that output
                                    and the action that maximizes rewards.
                                </p>

                                <p>
                                    For example, if the CartPole is currently travelling to the left, it is preferable to
                                    reverse that movement and begin travelling to the right. Thus, a desired output from the model is [0, 1]
                                    ([Going left, Going right]). A network without training won't necessarily generate that output.
                                    The optimizer's job is to adjust the network so that the vector approaches [0, 1] when the CartPole
                                    is moving left.
                                </p>

                                <br>

                                <img class = "card-img-top img-responsive" src = "images/RLModel.png" style = "width: 40%; display: block; margin: 10px auto 20px">

                                <br>

                                <h4>So our loss function attempts to minimize that difference. How are rewards used?</h4>

                                <p>
                                    We multiply our gradients by the rewards. When performing Back Propagation, positive rewards
                                    (agent did something right) will cause the optimizer to descend down the gradient. The
                                    opposite is true for negative rewards (agent did something wrong). This process has the effect of
                                    'learning' what the appropriate actions to take are, given a state from the environment.
                                </p>
                                <h4>The Credit Assignment Problem</h4>

                                <p>
                                    There is a fundamental problem with how rewards are calculated: how does the agent know if
                                    falling at t = 100 was caused by an action at t = 98 or t = 17? This is known as the 'Credit
                                    Assignment Problem'.
                                </p>
                                <p>
                                    To solve this problem, we apply a discount rate to our rewards. For each time step:
                                </p>
                                <p>
                                    <i>
                                        Discounted Reward [t = t] = Reward [t = t] * pow(discount_rate, 0) + ... + Reward [t = t + n]
                                        * pow(discount_rate, n)
                                    </i>
                                </p>
                                <p>
                                    Note: discount_rate belongs to (0, 1)
                                </p>
                                <p>
                                    What does this accomplish? This decreases the impact that a future reward has on the current time
                                    step. Using discounted rewards, the agent, over many games, is able to 'learn' what actions,
                                    given a corresponding input from the environment, are beneficial.
                                </p>

                                <h3>Model</h3>

                                <p>
                                    The tf.keras API was leveraged for the formulation of models. Each model architecture developed
                                    consisted of a series of fully-connected layers. Dropout was used for the final design; this
                                    design performed the best during testing.
                                </p>
                                <p>
                                    The final design, model_v5, consisted of the following:
                                </p>
                                <i>
                                    Dense(32) <span>&rarr;</span>
                                    Dropout <span>&rarr;</span>
                                    Dense(32) <span>&rarr;</span>
                                    Dropout <span>&rarr;</span>
                                    Dense(32) <span>&rarr;</span>
                                    Dropout <span>&rarr;</span>
                                    Dense(32) <span>&rarr;</span>
                                    Dropout <span>&rarr;</span>
                                    Dense(32) <span>&rarr;</span>
                                    Dense(2) <span>&rarr;</span>
                                    Softmax
                                </i>

                                <h3>Results</h3>

                                <p>
                                    After 5 iterations of the model architecture, a policy model was trained that converged and
                                    was able to survive in the environment. The program was manually
                                    stopped at 15,000 steps (about 5 minutes). It took 900 episodes of training to reach this point.
                                    Below is a video showing the agent's progress throughout the training loop.
                                </p>

                                <div class="embed-responsive embed-responsive-16by9">
                                    <video controls><source src = "videos/Training of Policy Model.mp4" type = "video/mp4"></video>
                                </div>

                                <br>

                                <h3>Acknowledgements</h3>

                                <p>
                                    Three resources were used to help me as I learned about Reinforcement Learning:
                                </p>
                                <ol>
                                    <li>I was introduced to the idea while completing Jose Portilla's
                                        <a style = "color: black" href = "https://www.udemy.com/course/complete-guide-to-tensorflow-for-deep-learning-with-python/" target = "_blank">
                                            Complete Guide to TensorFlow for Deep Learning with Python
                                        </a> course on Udemy.
                                    </li>
                                    <li>
                                        Much of the implementation for this project was inspired by this
                                        <a style = "color: black" href="https://medium.com/@hamza.emra/reinforcement-learning-with-tensorflow-2-0-cca33fead626" target = "_blank">
                                            Medium post.
                                        </a>
                                    </li>
                                    <li>
                                        This
                                        <a style = "color: black" href="https://medium.com/deep-math-machine-learning-ai/ch-13-deep-reinforcement-learning-deep-q-learning-and-policy-gradients-towards-agi-a2a0b611617e" target = "_blank">
                                            Medium post
                                        </a>
                                        provided much of the necessary background and basis for this project.
                                    </li>
                                </ol>

                            </div>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-header" id="headingTwo">
                            <h2 class="mb-0">
                                <button class="btn btn-link collapsed" type="button" data-toggle="collapse" data-target="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo">
                                    Handwritten Digit Classifier &nbsp<i class = "fa fa-arrow-down"></i>
                                </button>
                            </h2>
                        </div>


                        <div id="collapseTwo" class = "collapse" aria-labelledby="headingTwo" data-parent = "#accordionExample" style = "padding: 5px; padding-left: 10px; background-color: #616D7E;  color: #fff">
                            <p>
                                <script src="https://code.jquery.com/jquery-2.2.4.min.js"></script>
                                <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.5.2/dist/tf.min.js"></script>

                                <h3>Problem</h3>

                                The goal is to correctly classify a single handwritten digit given an arbitrary image.
                                To test out the performance of my model, click on the link below.

                                <br><br>

                                <a href = "Digit-Classifier.html" target = "_blank">
                                    <button class = "btn btn-light">
                                        Try it Out
                                    </button>
                                </a>

                                <br><br>

                                <h3>Approach</h3>

                                <div class = "row" style = "padding: 5px; padding-left: 10px">
                                    <div class = "col-md-6">
                                        <p>
                                            Machine Learning was used to solve this problem. Using the tf.keras API, a Convolutional
                                            Neural Network was trained on the MNIST dataset. The following model architecture was
                                            used.

                                            <br>
                                            <br>

                                            Thanks to Google, I was able to train on a state-of-the-art TPU (Tensor Processing Unit)
                                            through their free cloud service: Google Colab. On the MNIST dataset, I reached a
                                            validation accuracy of approximately 99.2%.

                                            <br>
                                            <br>

                                            It is important to note that the
                                            numbers of the MNIST dataset are written in pen, while we are using an HTML
                                            canvas to draw our numbers; this could slightly impact model performance.
                                        </p>
                                    </div>
                                    <div class = "col-md-6">
                                        <img src = "images/model.png" class = "card-img-top img-responsive" style = "margin-left: auto; margin-right: auto">
                                    </div>
                                </div>
                            </p>
                        </div>
                    </div>
                </div>

                <br>

                <h3 id = "contact" class = "font-weight-light animate-pop-in pop-title">Contact</h3>
                <hr>

                <footer class="site-footer animate-pop-in pop-secondary">
                    <div class="container">
                        <div class="row">

                            <div class="col-sm-12 col-md-6">
                                <h6>Contact Me</h6>
                                <p>
                                    If you have any questions about Machine Learning, Web Development, or the
                                    Engineering Program at the University of Waterloo, don't hesitate to reach out to
                                    me.
                                </p>
                            </div>

                            <div class="col-xs-6 col-md-3">
                                <h6>Quick Links</h6>
                                <ul class="footer-links">
                                    <li><a href="#home">Home</a></li>
                                    <li><a href="#about-me">About Me</a></li>
                                    <li><a href="#work-experience">Work Experience</a></li>
                                    <li><a href="#projects">Projects</a></li>
                                    <li><a href="#featured-work">Featured Work</a></li>
                                    <li><a href="#contact">Contact</a></li>
                                </ul>
                            </div>

                            <div class="col-xs-6 col-md-3">
                                <img src = "images/icon.png" style = "width: 100px">
                            </div>

                        </div>
                        <hr>
                    </div>
                    <div class="container">
                        <div class="row">
                            <div class="col-md-8 col-sm-6 col-xs-12">
                                <p class="copyright-text">
                                    Copyright &copy; 2020. All Rights Reserved by Michael Nasello.
                                </p>
                            </div>

                            <div id = "contact-icons" class="col-md-4 col-sm-6 col-xs-12">
                                <ul class="social-icons">
                                    <li><a title = "LinkedIn" class="linkedin" href="https://www.linkedin.com/in/michael-nasello" target = "_blank"><i class="fa fa-linkedin"></i></a></li>
                                    <li><a title = "GitHub" class="facebook" href="https://github.com/MichaelNasello" target = "_blank"><i class="fa fa-github"></i></a></li>
                                    <li><a title = "Email" class="twitter" href="mailto:mlnasell@uwaterloo.ca"><i class="fa fa-envelope"></i></a></li>
                                    <li><a title = "Resume" class="dribbble" href="https://drive.google.com/open?id=1oScBNeyEuKXIX5FqIq0hdXf17sW3vygC" target = "_blank"><i class="fa fa-file"></i></a></li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </footer>
            </div>
        </div>
    </div>

</body>
</html>